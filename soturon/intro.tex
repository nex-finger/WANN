\section{はじめに}
生物学における先天的能力(Precociality)とは，動物が生まれた瞬間からすでに持っている能力のことである．例えば，トカゲやヘビは生まれ持って捕食者から逃れる能力を有している．また，アヒルは孵化後すぐに泳いだり食事をすることができ，七面鳥は一度も見たことがない捕食者を視認するすることができる．これは，動物の脳は高度に構造化された状態で生まれ，その構造はゲノムに記憶されていることを意味する．Zadorは生物学的な学習について『動物の行動の多くは生得的なものであり学習によって生じるものではない．動物の脳はAI研究者が思い描くようななんでも学べる汎用的な学習アルゴリズムを備えた白紙の状態ではない．』と強調している\cite{先天的能力}．\\
Weight Agnostic Neural Networks(WANN)は，2019年にAdam GaierとDavid Haによって発表されたシナプス荷重に依存しないネットワークの探索アルゴリズムである\cite{WANN}．WANNは，NEAT\cite{NEAT}をベースに作られており，どのようなシナプス荷重においてもタスクを解ける性質をもつネットワーク，つまり構造自体にタスクを解く機能が備わっている．これは遺伝的アルゴリズム\cite{遺伝的アルゴリズム}を用いたNeuro-Evolution\cite{NE}の手法から実現できる．\\
WANNの個体変異の1つに，ノードの活性化関数の変更が行われる．隠れ層からランダムに選択されたノードの活性化関数は現在採用されている以外の活性化関数に同様に確からしく選択される．これは探索後期において，それまでの良かったノードの出力を反転させてしまう懸念がある．\\
本論文では，活性化関数を変更する際の確率を関数同士の距離関数が小さいほど選ばれやすいようにする手法を提案する．距離関数が小さいことは，関数同士が似ているを意味し，活性化関数の変更により出力の大きな変更が起こりにくくなる．距離関数には0付近の活性化関数同士の出力の差を積分と，実際にその個体が体験した入力ノードから推測できる該当ノードの出力の差の合計を採用する．\\
実験では \textbf{ここから追加}